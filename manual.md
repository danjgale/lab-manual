# fMRI Pipeline Manual

## Overview




## Converting raw DICOMs to NIfTI


### BIDS format


### Bidsify


#### Example 1: Single-session conversion

`$ bidsify -d dicom-directory -o bids-directory -c config.json`

`$ bidsify -d dicom-directory -o bids-directory -c config.json --ignore behaviour-folder`

#### Example 2: Multi-session conversion

`$ bidsify -d dicom-directory -o bids-directory -c config.json -s ses-01 -m submap.json`

`$ bidsify -d dicom-directory -o bids-directory -c config.json -s ses-02 -m submap.json`



## Minimal Preprocessing


### fMRIprep


## Data Extraction and Post-Processing

The final step in the pipeline is to obtain ready-to-analyze data from your preprocessed functional data. For pretty much all analyses other than conventional GLM-based analyses, these data are the timeseries for each region of interest in your project. Multivariate pattern analyses (MVPA; or any voxel-level analysis) requires the timeseries for each individual voxel in a region. Meanwhile, typical functional connectivity or BOLD timecourse analyses will average across voxels to generate a mean timeseries for a region. Ultimately, the goal is to have your data in a tabular format that can be loaded and analyzed by code of any programming language.  

In addition to extracting out the data, you will also need to apply some additional post-processing steps to ensure that you properly denoise the data. This can include temporal filtering, detrending, nuisance regression, spatial smoothing, and discarding initial unstable volumes of each scan.  Applying post-processing is especially important for functional connectivity analyses where noisy data can induce spurious correlations and false-positives in your data.   

### Niimasker

Data can be extracted and post-processed using [niimasker](https://github.com/danjgale/nii-masker), which takes in functional images and returns tabular data files of extracted and processed regions. niimasker is essentially a command-line interface for some key functions in [nilearn](https://nilearn.github.io/index.html) (the package that niimasker's name pays homage to) with some extra bells and whistles thrown in. In addition to extracting data, it generates reports for each data file it created, which fully documents the extraction and allows you to quickly inspect your data quality. 

niimasker has a flexible interface that lets you specify everything directly as a command-line argument or put everything in a `.json` file. I prefer the latter, as it is easier to set. Once installed (refer to its  documentation), simply call niimasker to view the help documentation:

`$ niimasker -h`

niimasker requires command line argument, the output folder, and the rest can be set either on the command line or in the `.json` file (whatever is set in the  `.json` file takes priority if both ways are used). I highly recommend using niimasker as so:

`$ niimasker your-output-directory/ -c config.json`

And then in `config.json` set everything there (defaults are shown below just for example's sake):

 ```json
{
  "input_files": [],
  "mask_img": "",
  "labels": [],
  "regressor_files": null,
  "regressor_names": [],
  "as_voxels": false,
  "standardize": false,
  "t_r": null,
  "detrend": false,
  "high_pass": null,
  "low_pass": null,
  "smoothing_fwhm": null,
  "discard_scans": null,
  "n_jobs": 1
}
 ```

Please refer to niimasker's documentation to learn more and familiarize yourself with how to use to use it. Next, I will go over some use-cases for typical analyses done in the lab. 

### Conventional GLM

Conventional GLM do not require data extraction and post-processing the same way that MVPA or functional connectivity analyses do because you feed the functional images directly into your GLM software of choice (SPM, FSL, nistats, etc.). However, you may want to perform an ROI analysis using the betaweights of your GLMs.  For this, you will first need to concatenate all of your betaweight images generated by these programs into a single image for each subject, so that the time domain of each image corresponds to the number of experimental conditions that you are interested in. You will also need a binary mask for an ROI or atlas file to define your regions. 

In a two subject example, a configuration would look similar to this:

```json
{
  "input_files": ["sub-01_betas.nii.gz", "sub-02_betas.nii.gz"],
  "mask_img": "roi_mask.nii.gz",
  "as_voxels": true
}
```

This is a really simple use-case that pulls out the "timeseries" for each voxel in the mask. The "timeseries" in this case is just the betaweight for each experimental condition because you concatenated the betaweight images for each condition. Because you are looking at betaweights, you do not need to apply any post-processing on the data. 

If you had an atlas file and were interested in multiple regions, the configuration file would be something like so:

```json
{
  "input_files": ["sub-01_betas.nii.gz", "sub-02_betas.nii.gz"],
  "mask_img": "your_atlas.nii.gz",
  "labels": atlas_labels.tsv
}
```

This would pull out the average betaweight of every experimental condition for each region defined by the atlas. 

### Multivariate pattern analyses

### Functional Connectivity



## 

## Glossary

